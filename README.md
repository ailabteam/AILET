# Dynamic Scheduling for Satellite QKD Networks via Deep Reinforcement Learning

This repository contains the source code and experimental setup for the paper titled *"Dynamic Scheduling for Satellite QKD Networks via Deep Reinforcement Learning"*, submitted to ACM AI Letters (AILET).

## Abstract

Satellite-based Quantum Key Distribution (QKD) is pivotal for future global secure communications. However, its efficiency is severely hampered by the dynamic nature of satellite-to-ground links, which are affected by orbital mechanics and unpredictable atmospheric conditions. Static or greedy scheduling strategies often lead to suboptimal network performance. In this paper, we propose a novel framework that leverages Deep Reinforcement Learning (DRL) to create an autonomous agent for dynamic scheduling in satellite QKD networks. We formulate the problem as a Markov Decision Process (MDP) where the agent's goal is to maximize the long-term cumulative secure key generation. Our simulation results demonstrate that the DRL agent significantly outperforms traditional greedy and static scheduling policies, paving the way for more efficient and autonomous management of future quantum networks.

## Repository Structure

```
.
├── models/                   # Saved trained models
├── logs/                     # TensorBoard logs for training
├── qkd_env.py                # The custom Gymnasium environment for the simulation
├── train.py                  # Script to train the DRL agent
├── evaluate.py               # Script to evaluate and compare agents
├── verify_gpu.py             # Utility to check PyTorch and GPU setup
├── policy_comparison.png     # Output figure: Comparison of total rewards
├── action_distribution.png   # Output figure: Comparison of action distributions
├── requirements.txt          # List of Python dependencies
└── README.md                 # This file
```

## Getting Started

### Prerequisites

- Python 3.9+
- NVIDIA GPU with CUDA drivers (recommended for training)
- Conda (recommended for environment management)

### Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/ailabteam/AILET.git
    cd AILET
    ```

2.  **Create and activate the Conda environment:**
    ```bash
    conda create -n qkd_rl python=3.10 -y
    conda activate qkd_rl
    ```

3.  **Install dependencies:**
    This project uses PyTorch. Please install the version compatible with your CUDA driver first. For CUDA 12.1, use:
    ```bash
    conda install pytorch torchvision toraudio pytorch-cuda=12.1 -c pytorch -c nvidia -y
    ```
    Then, install the remaining packages:
    ```bash
    pip install stable-baselines3[extra] gymnasium skyfield pandas matplotlib seaborn
    ```
    Alternatively, you can create a `requirements.txt` file and install using pip.

4.  **Verify GPU setup (Optional but recommended):**
    Run the verification script to ensure PyTorch can detect your GPU.
    ```bash
    python verify_gpu.py
    ```

## Usage

The workflow is divided into two main steps: training the agent and evaluating its performance.

### 1. Training the Agent

To train the Proximal Policy Optimization (PPO) agent, run the `train.py` script.

```bash
python train.py
```

This will:
- Create a `SatelliteQKDEnv` instance.
- Train the PPO model for a predefined number of timesteps.
- Save training logs to the `logs/` directory.
- Save model checkpoints and the final model to the `models/` directory.

You can monitor the training progress using TensorBoard:
```bash
tensorboard --logdir logs
```

### 2. Evaluating the Agent

After training is complete, a final model `ppo_qkd_model_final.zip` will be saved in the `models/` directory. To evaluate this model and compare it against baseline policies (Random and Greedy), run the `evaluate.py` script.

```bash
python evaluate.py
```

This script will:
- Load the trained DRL agent.
- Run a full simulation episode for the DRL agent, a Random agent, and a Greedy agent.
- Print the total secure key (reward) generated by each policy.
- Generate and save two high-quality figures (`.png` format, 600 DPI) in the root directory:
  - `policy_comparison.png`: A bar chart comparing the total performance of the policies.
  - `action_distribution.png`: A histogram comparing the action choices of each policy.

## Citing

If you use this code in your research, please consider citing our paper (citation details will be added upon publication).

```bibtex
@article{Do2025AILET,
  author    = {Do, Phuc Hao},
  title     = {Dynamic Scheduling for Satellite QKD Networks via Deep Reinforcement Learning},
  journal   = {ACM AI Letters},
  year      = {2025},
  % To be updated upon acceptance
}
```
